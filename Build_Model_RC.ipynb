{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8fab55",
   "metadata": {
    "id": "725c9c6d"
   },
   "source": [
    "# Install conda on your Colab environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d718d4",
   "metadata": {},
   "source": [
    "Ignore this first cell if you are running the notebook in a local environment.\n",
    "\n",
    "One can still run it locally but it will have no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709272e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40951,
     "status": "ok",
     "timestamp": 1664526150927,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "c4f08880",
    "outputId": "eaae29a9-4739-4b0f-a2a7-56bfa89f0bf0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell first - it will install a conda distribution (mamba)\n",
    "# on your Drive then restart the kernel automatically \n",
    "# (don't worry about the crashing/restarting kernel messages)\n",
    "# It HAS to be runned FIRST everytime you use the notebook in colab\n",
    "\n",
    "import os\n",
    "import sys\n",
    "RunningInCOLAB  = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00845727",
   "metadata": {},
   "source": [
    "# Set up your Colab or local environment\n",
    "# Then import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a48ec0",
   "metadata": {},
   "source": [
    "Run this cell in both cases of use (local or Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d16e11b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117260,
     "status": "ok",
     "timestamp": 1664526767265,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "BYwheAEcr-ME",
    "outputId": "8ba41a54-6751-4c00-ed1a-938db78cafb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['README.md', 'Duplicate_Model.ipynb', 'Build_Model_Dense.ipynb', 'Build_Dataset.py', 'Dataset_experimental', '.ipynb_checkpoints', '.git', 'Build_Experimental.ipynb', 'Reservoir', 'Dataset_model', 'Figures.ipynb', 'Result', 'Figures', '.gitignore', 'Duplicate_Model.py', 'LICENSE', 'Build_Dataset.ipynb', 'Dataset_input', '__pycache__', 'Build_Experimental.py', 'old', 'environment_amn.yml', 'Build_Model.py', 'Build_Model.ipynb', '.DS_Store']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "RunningInCOLAB  = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    \n",
    "    # Check everything is fine with conda in Colab\n",
    "    import condacolab\n",
    "    condacolab.check()\n",
    "    \n",
    "    # Mount your drive environment in the colab runtime\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    \n",
    "    # Change this variable to your path on Google Drive to which the repo has been cloned\n",
    "    # If you followed the colab notebook 'repo_cloning.ipynb', nothing to change here\n",
    "    repo_path_in_drive = '/content/drive/My Drive/Github/amn_release/'\n",
    "    # Change directory to your repo cloned in your drive\n",
    "    DIRECTORY = repo_path_in_drive\n",
    "    os.chdir(repo_path_in_drive)\n",
    "    # Copy the environment given in the environment_amn_light.yml\n",
    "    !mamba env update -n base -f environment_amn_light.yml\n",
    "    \n",
    "    # This is one of the few Colab-compatible font\n",
    "    font = 'Liberation Sans'\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # In this case the local root of the repo is our working directory\n",
    "    DIRECTORY = './'\n",
    "    font = 'arial'\n",
    "\n",
    "# printing the working directory files. One can check you see the same folders and files as in the git webpage.\n",
    "print(os.listdir(DIRECTORY))\n",
    "\n",
    "from Build_Model import *\n",
    "\n",
    "# We declare this function here and not in the\n",
    "# function-storing python file to modify it easily\n",
    "# as it can change the printouts of the methods\n",
    "def printout(filename, Stats, model, time): \n",
    "    # printing Stats\n",
    "    print('Stats for %s CPU-time %.4f' % (filename, time))\n",
    "    print('R2 = %.4f (+/- %.4f) Constraint = %.4f (+/- %.4f)' % \\\n",
    "          (Stats.train_objective[0], Stats.train_objective[1],\n",
    "           Stats.train_loss[0], Stats.train_loss[1]))\n",
    "    print('Q2 = %.4f (+/- %.4f) Constraint = %.4f (+/- %.4f)' % \\\n",
    "          (Stats.test_objective[0], Stats.test_objective[1],\n",
    "           Stats.test_loss[0], Stats.test_loss[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42adbd7a",
   "metadata": {
    "id": "3onjn3E-S9ZT",
    "tags": []
   },
   "source": [
    "## (4) Reservoir computing with experimental data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0016d2f2",
   "metadata": {
    "id": "8EA8mgwAS9ZU",
    "outputId": "d245ae2b-d691-4d35-8b73-70cf5623f8be",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reactions:  550 550\n",
      "number of metabolites:  1083\n",
      "filtered measurements size:  1\n",
      "RC reservoir file: ./Reservoir/iML1515_UB_AMN_QP\n",
      "RC model type: RC_AMN\n",
      "RC scaler: 0.0\n",
      "RC model input dim: 38\n",
      "RC model output dim: 1\n",
      "RC model medium bound: UB\n",
      "training set size (110, 38) (110, 1)\n",
      "reservoir S, Pin, Pout matrices (1083, 550) (38, 550) (1, 550)\n",
      "RC training epochs: 1000\n",
      "RC training regression: True\n",
      "RC training learn rate: 0.0001\n",
      "RC training dropout: 0.25\n",
      "RC training batch size: 5\n",
      "RC training validation iter: 0\n",
      "RC training xfold: 0\n",
      "RC training early stopping: False\n",
      "--------prior network --------\n",
      "training file: None\n",
      "model type: ANN_Dense\n",
      "model scaler: 0.0\n",
      "model input dim: 10\n",
      "model output dim: 10\n",
      "model medium bound: \n",
      "timestep: 0\n",
      "no training set provided\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 500\n",
      "activation function: relu\n",
      "--------reservoir network-----\n",
      "training file: ./Dataset_model/iML1515_UB\n",
      "model type: AMN_QP\n",
      "model scaler: 11.0\n",
      "model input dim: 38\n",
      "model output dim: 1104\n",
      "model medium bound: UB\n",
      "timestep: 0\n",
      "training set size (11000, 38) (11000, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 500\n",
      "activation function: relu\n",
      "training epochs: 500\n",
      "training regression: True\n",
      "training learn rate: 0.001\n",
      "training dropout: 0.25\n",
      "training batch size: 5\n",
      "training validation iter: 0\n",
      "training xfold: 0\n",
      "training early stopping: False\n",
      "AMN scaler 0.0\n",
      "RC input shape (110, 38) (110, 4)\n",
      "Dense layer n_hidden, hidden_dim, output_dim, activation, trainable: 1 500 10 relu True\n",
      "Prior inputs and outputs (None, 10) (None, 10)\n",
      "Res inputs added to Prior_outputs 28\n",
      "Res inputs (final) (None, 38)\n",
      "Dense layer n_hidden, hidden_dim, output_dim, activation, trainable: 1 500 550 relu False\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (None, 1) (None, 1) (None, 1) (None, 1) (None, 550) (None, 1104)\n",
      "Res_outputs-------------------- (None, 1104)\n",
      "SV, PinV, Vpos, V-------------- (None, 1) (None, 1) (None, 1) (None, 550)\n",
      "nbr parameters: 305560\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Loss out on V0:  -1\n",
      "Loss constraint on V0:  -1\n",
      "Loss all on V0:  -1\n",
      "Loss out on Vf:  0.0084753195\n",
      "Loss constraint on Vf:  5.3953863e-07\n",
      "Loss all on Vf:  4.445708e-05\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Loss out on V0:  -1\n",
      "Loss constraint on V0:  -1\n",
      "Loss all on V0:  -1\n",
      "Loss out on Vf:  0.0084753195\n",
      "Loss constraint on Vf:  5.3953863e-07\n",
      "Loss all on Vf:  4.445708e-05\n",
      "train = 0.98 test = 0.98 loss-train = 0.000001 loss-test = 0.000001 iter=0\n",
      "Stats for iML1515_UB_AMN_QP CPU-time 104.3438\n",
      "R2 = 0.9752 (+/- 0.0000) Constraint = 0.0000 (+/- 0.0000)\n",
      "Q2 = 0.9752 (+/- 0.0000) Constraint = 0.0000 (+/- 0.0000)\n",
      "Iter 0 Collated Q2 0.9752191448432519\n",
      "number of reactions:  550 550\n",
      "number of metabolites:  1083\n",
      "filtered measurements size:  1\n",
      "RC reservoir file: ./Reservoir/iML1515_UB_AMN_QP\n",
      "RC model type: RC_AMN\n",
      "RC scaler: 0.0\n",
      "RC model input dim: 38\n",
      "RC model output dim: 1\n",
      "RC model medium bound: UB\n",
      "training set size (110, 38) (110, 1)\n",
      "reservoir S, Pin, Pout matrices (1083, 550) (38, 550) (1, 550)\n",
      "RC training epochs: 1000\n",
      "RC training regression: True\n",
      "RC training learn rate: 0.0001\n",
      "RC training dropout: 0.25\n",
      "RC training batch size: 5\n",
      "RC training validation iter: 0\n",
      "RC training xfold: 0\n",
      "RC training early stopping: False\n",
      "--------prior network --------\n",
      "training file: None\n",
      "model type: ANN_Dense\n",
      "model scaler: 0.0\n",
      "model input dim: 10\n",
      "model output dim: 10\n",
      "model medium bound: \n",
      "timestep: 0\n",
      "no training set provided\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 500\n",
      "activation function: relu\n",
      "--------reservoir network-----\n",
      "training file: ./Dataset_model/iML1515_UB\n",
      "model type: AMN_QP\n",
      "model scaler: 11.0\n",
      "model input dim: 38\n",
      "model output dim: 1104\n",
      "model medium bound: UB\n",
      "timestep: 0\n",
      "training set size (11000, 38) (11000, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 500\n",
      "activation function: relu\n",
      "training epochs: 500\n",
      "training regression: True\n",
      "training learn rate: 0.001\n",
      "training dropout: 0.25\n",
      "training batch size: 5\n",
      "training validation iter: 0\n",
      "training xfold: 0\n",
      "training early stopping: False\n",
      "AMN scaler 0.0\n",
      "RC input shape (110, 38) (110, 4)\n",
      "Dense layer n_hidden, hidden_dim, output_dim, activation, trainable: 1 500 10 relu True\n",
      "Prior inputs and outputs (None, 10) (None, 10)\n",
      "Res inputs added to Prior_outputs 28\n",
      "Res inputs (final) (None, 38)\n",
      "Dense layer n_hidden, hidden_dim, output_dim, activation, trainable: 1 500 550 relu False\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (None, 1) (None, 1) (None, 1) (None, 1) (None, 550) (None, 1104)\n",
      "Res_outputs-------------------- (None, 1104)\n",
      "SV, PinV, Vpos, V-------------- (None, 1) (None, 1) (None, 1) (None, 550)\n",
      "nbr parameters: 305560\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Loss out on V0:  -1\n",
      "Loss constraint on V0:  -1\n",
      "Loss all on V0:  -1\n",
      "Loss out on Vf:  0.008912701\n",
      "Loss constraint on Vf:  5.3859395e-07\n",
      "Loss all on Vf:  4.6406967e-05\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Loss out on V0:  -1\n",
      "Loss constraint on V0:  -1\n",
      "Loss all on V0:  -1\n",
      "Loss out on Vf:  0.008912701\n",
      "Loss constraint on Vf:  5.3859395e-07\n",
      "Loss all on Vf:  4.6406967e-05\n",
      "train = 0.97 test = 0.97 loss-train = 0.000001 loss-test = 0.000001 iter=0\n",
      "Stats for iML1515_UB_AMN_QP CPU-time 97.2189\n",
      "R2 = 0.9741 (+/- 0.0000) Constraint = 0.0000 (+/- 0.0000)\n",
      "Q2 = 0.9741 (+/- 0.0000) Constraint = 0.0000 (+/- 0.0000)\n",
      "Iter 1 Collated Q2 0.9741218740170711\n",
      "number of reactions:  550 550\n",
      "number of metabolites:  1083\n",
      "filtered measurements size:  1\n",
      "RC reservoir file: ./Reservoir/iML1515_UB_AMN_QP\n",
      "RC model type: RC_AMN\n",
      "RC scaler: 0.0\n",
      "RC model input dim: 38\n",
      "RC model output dim: 1\n",
      "RC model medium bound: UB\n",
      "training set size (110, 38) (110, 1)\n",
      "reservoir S, Pin, Pout matrices (1083, 550) (38, 550) (1, 550)\n",
      "RC training epochs: 1000\n",
      "RC training regression: True\n",
      "RC training learn rate: 0.0001\n",
      "RC training dropout: 0.25\n",
      "RC training batch size: 5\n",
      "RC training validation iter: 0\n",
      "RC training xfold: 0\n",
      "RC training early stopping: False\n",
      "--------prior network --------\n",
      "training file: None\n",
      "model type: ANN_Dense\n",
      "model scaler: 0.0\n",
      "model input dim: 10\n",
      "model output dim: 10\n",
      "model medium bound: \n",
      "timestep: 0\n",
      "no training set provided\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 500\n",
      "activation function: relu\n",
      "--------reservoir network-----\n",
      "training file: ./Dataset_model/iML1515_UB\n",
      "model type: AMN_QP\n",
      "model scaler: 11.0\n",
      "model input dim: 38\n",
      "model output dim: 1104\n",
      "model medium bound: UB\n",
      "timestep: 0\n",
      "training set size (11000, 38) (11000, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 500\n",
      "activation function: relu\n",
      "training epochs: 500\n",
      "training regression: True\n",
      "training learn rate: 0.001\n",
      "training dropout: 0.25\n",
      "training batch size: 5\n",
      "training validation iter: 0\n",
      "training xfold: 0\n",
      "training early stopping: False\n",
      "AMN scaler 0.0\n",
      "RC input shape (110, 38) (110, 4)\n",
      "Dense layer n_hidden, hidden_dim, output_dim, activation, trainable: 1 500 10 relu True\n",
      "Prior inputs and outputs (None, 10) (None, 10)\n",
      "Res inputs added to Prior_outputs 28\n",
      "Res inputs (final) (None, 38)\n",
      "Dense layer n_hidden, hidden_dim, output_dim, activation, trainable: 1 500 550 relu False\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (None, 1) (None, 1) (None, 1) (None, 1) (None, 550) (None, 1104)\n",
      "Res_outputs-------------------- (None, 1104)\n",
      "SV, PinV, Vpos, V-------------- (None, 1) (None, 1) (None, 1) (None, 550)\n",
      "nbr parameters: 305560\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Loss out on V0:  -1\n",
      "Loss constraint on V0:  -1\n",
      "Loss all on V0:  -1\n",
      "Loss out on Vf:  0.00819272\n",
      "Loss constraint on Vf:  5.45585e-07\n",
      "Loss all on Vf:  4.3854223e-05\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Loss out on V0:  -1\n",
      "Loss constraint on V0:  -1\n",
      "Loss all on V0:  -1\n",
      "Loss out on Vf:  0.00819272\n",
      "Loss constraint on Vf:  5.45585e-07\n",
      "Loss all on Vf:  4.3854223e-05\n",
      "train = 0.98 test = 0.98 loss-train = 0.000001 loss-test = 0.000001 iter=0\n",
      "Stats for iML1515_UB_AMN_QP CPU-time 90.2241\n",
      "R2 = 0.9756 (+/- 0.0000) Constraint = 0.0000 (+/- 0.0000)\n",
      "Q2 = 0.9756 (+/- 0.0000) Constraint = 0.0000 (+/- 0.0000)\n",
      "Iter 2 Collated Q2 0.9755608195779709\n",
      "(3, 110, 592)\n",
      "Averaged Q2 = 0.9750 (+/- 0.0006)\n",
      "Loss SV average 0.0012 max 0.0022\n",
      "Loss Vin average 0.0000 max 0.0000\n",
      "Loss Vpos average 0.0000 max 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Create, train and evaluate RC models on experimental training set \n",
    "# Repeat the process with different seeds\n",
    "# This cell takes several hours to execute\n",
    "\n",
    "seed = 10\n",
    "Maxloop, Q2, PRED = 3, [], []  \n",
    "for Nloop in range(Maxloop):\n",
    "    # What you can change \n",
    "    seed = Nloop\n",
    "    np.random.seed(seed=seed)  \n",
    "    trainname = 'iML1515_EXP'\n",
    "    reservoirname = 'iML1515_UB_AMN_QP'\n",
    "    # End of What you can change\n",
    "  \n",
    "    # Create model \n",
    "    trainingfile = DIRECTORY+'Dataset_input/'+trainname\n",
    "    reservoirfile = DIRECTORY+'Reservoir/'+reservoirname\n",
    "    X, Y = read_XY(trainingfile, 38)\n",
    "    model = RC_Model(reservoirfile = reservoirfile, X=X, Y=Y, \n",
    "                n_hidden_prior = 1, hidden_dim_prior = 500, activation_prior = 'relu',\n",
    "                epochs = 1000, train_rate = 1.0e-4, xfold = 0,\n",
    "                verbose=True) \n",
    "    model.printout()\n",
    "\n",
    "    # Train and evaluate\n",
    "    start_time = time.time()\n",
    "    reservoir, pred, stats, _ = train_evaluate_model(model, verbose=True)\n",
    "    delta_time = time.time() - start_time\n",
    "\n",
    "    # Printing cross-validation results\n",
    "    printout(reservoirname, stats, model, delta_time)\n",
    "    r2 = r2_score(model.Y, pred[:,0], multioutput='variance_weighted')\n",
    "    print('Iter', Nloop, 'Collated Q2', r2)\n",
    "    Q2.append(r2)\n",
    "    PRED.append(pred)\n",
    "\n",
    "# Some printings and savings\n",
    "Q2, PRED = np.asarray(Q2), np.asarray(PRED)\n",
    "print(PRED.shape)\n",
    "obj = PRED[:,:,0]\n",
    "print('Averaged Q2 = %.4f (+/- %.4f)' % (np.mean(Q2), np.std(Q2)))\n",
    "filename = DIRECTORY+'Result/'+reservoirname+'_'\\\n",
    "+str(model.model_type)+'_Q2.csv'\n",
    "np.savetxt(filename, Q2, delimiter=',')\n",
    "filename = DIRECTORY+'Result/'+reservoirname+'_'\\\n",
    "+str(model.model_type)+'_PRED.csv'\n",
    "np.savetxt(filename, obj, delimiter=',')\n",
    "\n",
    "# Saving input / output of the first prediction for Cobra runs\n",
    "pred, obj = PRED[0], pred[:,0]\n",
    "Loss_SV, Loss_Vin, Loss_Vpos = pred[:,1], pred[:,2], pred[:,3]\n",
    "print('Loss SV average %.4f max %.4f' % (np.mean(Loss_SV), np.max(Loss_SV)))\n",
    "print('Loss Vin average %.4f max %.4f' % (np.mean(Loss_Vin), np.max(Loss_Vin)))\n",
    "print('Loss Vpos average %.4f max %.4f' % (np.mean(Loss_Vpos), np.max(Loss_Vpos)))\n",
    "V = pred[:, 4:4+model.S.shape[1]]\n",
    "Vin = pred[:, 4+model.S.shape[1]:]\n",
    "Vin = model.res.scaler * Vin # rescale back for Cobra\n",
    "XY = np.concatenate((Vin, Y), axis=1)\n",
    "filename = DIRECTORY+'Result/'+reservoirname+'_'\\\n",
    "+str(model.model_type)+'_solution_for_Cobra.csv'\n",
    "np.savetxt(filename, XY, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df35d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "amn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
