{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db205a17",
   "metadata": {
    "id": "725c9c6d",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Install conda on your Colab environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83743668",
   "metadata": {},
   "source": [
    "Ignore this first cell if you are running the notebook in a local environment.\n",
    "\n",
    "One can still run it locally but it will have no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f370c2ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40951,
     "status": "ok",
     "timestamp": 1664526150927,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "c4f08880",
    "outputId": "eaae29a9-4739-4b0f-a2a7-56bfa89f0bf0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell first - it will install a conda distribution (mamba)\n",
    "# on your Drive then restart the kernel automatically \n",
    "# (don't worry about the crashing/restarting kernel messages)\n",
    "# It HAS to be runned FIRST everytime you use the notebook in colab\n",
    "\n",
    "import os\n",
    "import sys\n",
    "RunningInCOLAB  = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27efe727",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Set up your Colab or local environment\n",
    "# Then import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a22f5c2",
   "metadata": {},
   "source": [
    "Run this cell in both cases of use (local or Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f992e59e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117260,
     "status": "ok",
     "timestamp": 1664526767265,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "BYwheAEcr-ME",
    "outputId": "8ba41a54-6751-4c00-ed1a-938db78cafb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['README.md', 'Duplicate_Model.ipynb', 'Build_Model_Dense.ipynb', 'Dataset_experimental', '.ipynb_checkpoints', '.git', 'Build_Model_RC.ipynb', 'environment_amn_light.yml', 'Build_Experimental.ipynb', 'Reservoir', 'Build_Model_MM.ipynb', 'Dataset_model', 'Figures.ipynb', 'Result', 'Figures', '.gitignore', 'LICENSE', 'Build_Model_ANN.ipynb', 'Build_Dataset.ipynb', 'Dataset_input', 'Functions', '__pycache__', 'old', 'environment_amn.yml', 'Build_Model_AMN.ipynb', 'Build_Model.ipynb', '.DS_Store']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "RunningInCOLAB  = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    \n",
    "    # Check everything is fine with conda in Colab\n",
    "    import condacolab\n",
    "    condacolab.check()\n",
    "    \n",
    "    # Mount your drive environment in the colab runtime\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    \n",
    "    # Change this variable to your path on Google Drive to which the repo has been cloned\n",
    "    # If you followed the colab notebook 'repo_cloning.ipynb', nothing to change here\n",
    "    repo_path_in_drive = '/content/drive/My Drive/Github/amn_release/'\n",
    "    # Change directory to your repo cloned in your drive\n",
    "    DIRECTORY = repo_path_in_drive\n",
    "    os.chdir(repo_path_in_drive)\n",
    "    # Copy the environment given in the environment_amn_light.yml\n",
    "    !mamba env update -n base -f environment_amn_light.yml\n",
    "    \n",
    "    # This is one of the few Colab-compatible font\n",
    "    font = 'Liberation Sans'\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # In this case the local root of the repo is our working directory\n",
    "    DIRECTORY = './'\n",
    "    font = 'arial'\n",
    "\n",
    "# printing the working directory files. One can check you see the same folders and files as in the git webpage.\n",
    "print(os.listdir(DIRECTORY))\n",
    "\n",
    "from Library.Build_Model import *\n",
    "\n",
    "# We declare this function here and not in the\n",
    "# function-storing python file to modify it easily\n",
    "# as it can change the printouts of the methods\n",
    "def printout(V, Stats, model): \n",
    "    # printing Stats\n",
    "    print(\"R2 = %.2f (+/- %.2f) Constraint = %.2f (+/- %.2f)\" % \\\n",
    "          (Stats.train_objective[0], Stats.train_objective[1],\n",
    "           Stats.train_loss[0], Stats.train_loss[1]))\n",
    "    Vout = tf.convert_to_tensor(np.float32(model.Y))\n",
    "    Loss_norm, dLoss = Loss_Vout(V, model.Pout, Vout)\n",
    "    print('Loss Targets', np.mean(Loss_norm))\n",
    "    Loss_norm, dLoss = Loss_SV(V, model.S)\n",
    "    print('Loss SV', np.mean(Loss_norm))\n",
    "    Vin = tf.convert_to_tensor(np.float32(model.X))\n",
    "    Pin = tf.convert_to_tensor(np.float32(model.Pin))\n",
    "    if Vin.shape[1] == model.S.shape[1]: # special case\n",
    "        Vin  = tf.linalg.matmul(Vin, tf.transpose(Pin), b_is_sparse=True)\n",
    "    Loss_norm, dLoss = Loss_Vin(V, model.Pin, Vin, model.mediumbound)\n",
    "    print('Loss Vin bound', np.mean(Loss_norm))\n",
    "    Loss_norm, dLoss = Loss_Vpos(V, model)\n",
    "    print('Loss V positive', np.mean(Loss_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25a673",
   "metadata": {
    "id": "Zyr9Xws9S9XX",
    "tags": []
   },
   "source": [
    "# Mechanistic Models\n",
    "\n",
    "# Examples with non-trainable mechanistic models, using FBA simulated training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d75779-907e-4aa6-901e-f76c3cbd8950",
   "metadata": {},
   "source": [
    "In both LP and QP solver, one can change the `trainname` suffix (EB or UB) to use exact or upper bounds as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e5494-cac7-464e-8884-4b288778c363",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LP solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9392b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 262268,
     "status": "ok",
     "timestamp": 1658840813297,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "xRQNL58CS9Xd",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "9c9e2fcc-453c-44b9-84a1-4cc0cb6d5221",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: ./Dataset_model/e_coli_core_UB\n",
      "model type: MM_LP\n",
      "model scaler: 0.0\n",
      "model input dim: 20\n",
      "model output dim: 1\n",
      "model medium bound: UB\n",
      "timestep: 10000\n",
      "training set size (10, 20) (10, 1)\n",
      "LP-Loss 1 0.25261024 0.06849076\n",
      "LP-Loss 10 0.2294474 0.06633821\n",
      "LP-Loss 100 0.0808966 0.03674851\n",
      "LP-Loss 1000 0.00023186656 0.0002091549\n",
      "LP-Loss 2000 3.8031656e-05 2.6454396e-05\n",
      "LP-Loss 3000 1.6315684e-05 1.6629287e-05\n",
      "LP-Loss 4000 9.442818e-06 1.449519e-05\n",
      "LP-Loss 5000 7.2193407e-06 1.2035626e-05\n",
      "LP-Loss 6000 5.5323576e-06 9.809663e-06\n",
      "LP-Loss 7000 4.2318406e-06 7.880076e-06\n",
      "LP-Loss 8000 3.2548737e-06 6.2515983e-06\n",
      "LP-Loss 9000 2.3623904e-06 4.757077e-06\n",
      "LP-Loss 10000 1.6831349e-06 3.5644443e-06\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 312)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.00 (+/- 0.00)\n",
      "Loss Targets 0.001244092\n",
      "Loss SV 8.0880665e-07\n",
      "Loss Vin bound 1.0041353e-05\n",
      "Loss V positive 2.924077e-06\n"
     ]
    }
   ],
   "source": [
    "# Run Mechanistic model (no training) QP (quadratic program) or LP (linear program)\n",
    "# using E. coli core simulation training sets and EB (or UB) bounds\n",
    "\n",
    "# What you can change\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "trainname = 'e_coli_core_UB' # the training set file name\n",
    "size = 10 # number of runs must be lower than the number of element in trainname\n",
    "timestep = int(1.0e4) # LP 1.0e4 QP 1.0e5\n",
    "learn_rate = 0.3 # LP 0.3 QP 1.0\n",
    "decay_rate = 0.9 # only in QP, UB 0.333 EB 0.9\n",
    "# End of What you can change\n",
    "\n",
    "# Create model and run GD for X and Y randomly drawn from trainingfile\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "model = Neural_Model(trainingfile = trainingfile, \n",
    "              objective=['BIOMASS_Ecoli_core_w_GAM'], \n",
    "              model_type = 'MM_LP', \n",
    "              timestep = timestep, \n",
    "              learn_rate = learn_rate, \n",
    "              decay_rate = decay_rate)\n",
    "\n",
    "# Select a random subset of the training set (of specified size)\n",
    "# With LP we also have to change b_ext and b_int accordingly\n",
    "ID = np.random.choice(model.X.shape[0], size, replace=False)\n",
    "model.X, model.Y = model.X[ID,:], model.Y[ID,:]\n",
    "if model.mediumbound == 'UB':\n",
    "    model.b_ext = model.b_ext[ID,:]\n",
    "if model.mediumbound == 'EB':\n",
    "    model.b_int = model.b_int[ID,:]\n",
    "\n",
    "# Prints a summary of the model before running\n",
    "model.printout()\n",
    "\n",
    "# Runs the appropriate method\n",
    "Ypred, Stats = MM_LP(model, verbose=True)\n",
    "\n",
    "# Printing results\n",
    "printout(Ypred, Stats, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3925af0b-bc82-4a6b-b34c-585a0900cef7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## QP solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abc769",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "executionInfo": {
     "elapsed": 41456,
     "status": "error",
     "timestamp": 1658841139912,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "4aijtPpxS9Xe",
    "outputId": "46a476d3-3521-4c37-ae52-6d10cd29873c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run Mechanistic model (no training) QP (quadratic program) or LP (linear program)\n",
    "# using E. coli core simulation training sets and EB (or UB) bounds\n",
    "\n",
    "# What you can change\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "trainname = 'e_coli_core_EB' # the training set file name\n",
    "size = 10 # number of runs must be lower than the number of element in trainname\n",
    "timestep = int(1.0e6) # LP 1.0e4 QP 1.0e5\n",
    "learn_rate = 1.0 # LP 0.3 QP 1.0\n",
    "decay_rate = 0.9 # only in QP, UB 0.333 EB 0.9\n",
    "# End of What you can change\n",
    "\n",
    "# Create model and run GD for X and Y randomly drawn from trainingfile\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "model = Neural_Model(trainingfile = trainingfile, \n",
    "              objective=['BIOMASS_Ecoli_core_w_GAM'], \n",
    "              model_type = 'MM_QP', \n",
    "              timestep = timestep, \n",
    "              learn_rate = learn_rate, \n",
    "              decay_rate = decay_rate)\n",
    "\n",
    "# Select a random subset of the training set (of specified size)\n",
    "ID = np.random.choice(model.X.shape[0], size, replace=False)\n",
    "model.X, model.Y = model.X[ID,:], model.Y[ID,:]\n",
    "\n",
    "# Prints a summary of the model before running\n",
    "model.printout()\n",
    "\n",
    "# Runs the appropriate method\n",
    "if model.model_type is 'MM_QP':\n",
    "    Ypred, Stats = MM_QP(model, verbose=True)\n",
    "\n",
    "# Printing results\n",
    "printout(Ypred, Stats, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
