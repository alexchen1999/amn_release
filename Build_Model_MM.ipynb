{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b97d3a",
   "metadata": {
    "id": "725c9c6d"
   },
   "source": [
    "# Install conda on your Colab environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8013d43",
   "metadata": {},
   "source": [
    "Ignore this first cell if you are running the notebook in a local environment.\n",
    "\n",
    "One can still run it locally but it will have no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de729b4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40951,
     "status": "ok",
     "timestamp": 1664526150927,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "c4f08880",
    "outputId": "eaae29a9-4739-4b0f-a2a7-56bfa89f0bf0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell first - it will install a conda distribution (mamba)\n",
    "# on your Drive then restart the kernel automatically \n",
    "# (don't worry about the crashing/restarting kernel messages)\n",
    "# It HAS to be runned FIRST everytime you use the notebook in colab\n",
    "\n",
    "import os\n",
    "import sys\n",
    "RunningInCOLAB  = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc9a570",
   "metadata": {},
   "source": [
    "# Set up your Colab or local environment\n",
    "# Then import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5530a36",
   "metadata": {},
   "source": [
    "Run this cell in both cases of use (local or Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc44fffe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117260,
     "status": "ok",
     "timestamp": 1664526767265,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "BYwheAEcr-ME",
    "outputId": "8ba41a54-6751-4c00-ed1a-938db78cafb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['README.md', 'Duplicate_Model.ipynb', 'Build_Model_Dense.ipynb', 'Dataset_experimental', '.ipynb_checkpoints', '.git', 'Build_Model_RC.ipynb', 'environment_amn_light.yml', 'Build_Experimental.ipynb', 'Reservoir', 'Build_Model_MM.ipynb', 'Dataset_model', 'Figures.ipynb', 'Result', 'Figures', '.gitignore', 'LICENSE', 'Build_Model_ANN.ipynb', 'Build_Dataset.ipynb', 'Dataset_input', 'Functions', '__pycache__', 'old', 'environment_amn.yml', 'Build_Model_AMN.ipynb', 'Build_Model.ipynb', '.DS_Store']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "RunningInCOLAB  = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    \n",
    "    # Check everything is fine with conda in Colab\n",
    "    import condacolab\n",
    "    condacolab.check()\n",
    "    \n",
    "    # Mount your drive environment in the colab runtime\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    \n",
    "    # Change this variable to your path on Google Drive to which the repo has been cloned\n",
    "    # If you followed the colab notebook 'repo_cloning.ipynb', nothing to change here\n",
    "    repo_path_in_drive = '/content/drive/My Drive/Github/amn_release/'\n",
    "    # Change directory to your repo cloned in your drive\n",
    "    DIRECTORY = repo_path_in_drive\n",
    "    os.chdir(repo_path_in_drive)\n",
    "    # Copy the environment given in the environment_amn_light.yml\n",
    "    !mamba env update -n base -f environment_amn_light.yml\n",
    "    \n",
    "    # This is one of the few Colab-compatible font\n",
    "    font = 'Liberation Sans'\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # In this case the local root of the repo is our working directory\n",
    "    DIRECTORY = './'\n",
    "    font = 'arial'\n",
    "\n",
    "# printing the working directory files. One can check you see the same folders and files as in the git webpage.\n",
    "print(os.listdir(DIRECTORY))\n",
    "\n",
    "from Functions.Build_Model import *\n",
    "\n",
    "# We declare this function here and not in the\n",
    "# function-storing python file to modify it easily\n",
    "# as it can change the printouts of the methods\n",
    "def printout(V, Stats, model): \n",
    "    # printing Stats\n",
    "    print(\"R2 = %.2f (+/- %.2f) Constraint = %.2f (+/- %.2f)\" % \\\n",
    "          (Stats.train_objective[0], Stats.train_objective[1],\n",
    "           Stats.train_loss[0], Stats.train_loss[1]))\n",
    "    Vout = tf.convert_to_tensor(np.float32(model.Y))\n",
    "    Loss_norm, dLoss = Loss_Vout(V, model.Pout, Vout)\n",
    "    print('Loss Targets', np.mean(Loss_norm))\n",
    "    Loss_norm, dLoss = Loss_SV(V, model.S)\n",
    "    print('Loss SV', np.mean(Loss_norm))\n",
    "    Vin = tf.convert_to_tensor(np.float32(model.X))\n",
    "    Pin = tf.convert_to_tensor(np.float32(model.Pin))\n",
    "    if Vin.shape[1] == model.S.shape[1]: # special case\n",
    "        Vin  = tf.linalg.matmul(Vin, tf.transpose(Pin), b_is_sparse=True)\n",
    "    Loss_norm, dLoss = Loss_Vin(V, model.Pin, Vin, model.mediumbound)\n",
    "    print('Loss Vin bound', np.mean(Loss_norm))\n",
    "    Loss_norm, dLoss = Loss_Vpos(V, model)\n",
    "    print('Loss V positive', np.mean(Loss_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d8c99",
   "metadata": {
    "id": "Zyr9Xws9S9XX",
    "tags": []
   },
   "source": [
    "## (1) Mechanistic Model: examples with non trainable mechanistic model with FBA simulated training sets or experimental datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c2400df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5876,
     "status": "ok",
     "timestamp": 1658841432653,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "KR8UqJUDS9Xb",
    "outputId": "15f24458-843d-4933-93f2-676483192958",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Dataset_model/tiny5_EB.npz\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "parameter file not found",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m parameter file not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lfaure/miniconda3/envs/AMN/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Run Mechanistic model (no training) QP (quadratic program) or LP (linear program)\n",
    "# using tiny5 simulation training sets with EB (or UB) bounds\n",
    "\n",
    "# What you can change\n",
    "seed = 1\n",
    "np.random.seed(seed=seed)  \n",
    "trainname = 'tiny5_EB'\n",
    "write_loss = False # Writes an output file containing loss history mean and std over timesteps\n",
    "write_targets = False # Writes an output file containing true and predicted targets\n",
    "# End of What you can change\n",
    "\n",
    "# Create model and run GD\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "model = Neural_Model(trainingfile = trainingfile, \n",
    "              objective=['biomass'], \n",
    "              model_type = 'MM_LP',\n",
    "              timestep = int(1.0e3), learn_rate = 1.0, decay_rate = 0.5)\n",
    "model.printout()\n",
    "\n",
    "loss_outname = DIRECTORY + \"Result/\" + model.model_type + \"_Loss_\" + trainname + \".csv\" if write_loss else None\n",
    "model.loss_outfile = loss_outname\n",
    "targets_outname = DIRECTORY + \"Result/\" + model.model_type + \"_Targets_\" + trainname + \".csv\" if write_targets else None\n",
    "model.targets_outfile = targets_outname\n",
    "\n",
    "if model.model_type is 'MM_QP':\n",
    "    Ypred, Stats = MM_QP(model, verbose=True)\n",
    "if model.model_type is 'MM_LP':\n",
    "    Ypred, Stats = MM_LP(model, verbose=True)\n",
    "\n",
    "# Printing results\n",
    "printout(Ypred, Stats, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a391cca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262268,
     "status": "ok",
     "timestamp": 1658840813297,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "xRQNL58CS9Xd",
    "outputId": "9c9e2fcc-453c-44b9-84a1-4cc0cb6d5221",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: ./Dataset_model/e_coli_core_UB\n",
      "model type: MM_LP\n",
      "model scaler: 0.0\n",
      "model input dim: 20\n",
      "model output dim: 1\n",
      "model medium bound: UB\n",
      "timestep: 10000\n",
      "training set size (10, 20) (10, 1)\n",
      "LP-Loss 1 0.25261024 0.06849076\n",
      "LP-Loss 10 0.2294474 0.06633821\n",
      "LP-Loss 100 0.0808966 0.03674851\n",
      "LP-Loss 1000 0.00023186656 0.0002091549\n",
      "LP-Loss 2000 3.8031656e-05 2.6454396e-05\n",
      "LP-Loss 3000 1.6315684e-05 1.6629287e-05\n",
      "LP-Loss 4000 9.442818e-06 1.449519e-05\n",
      "LP-Loss 5000 7.2193407e-06 1.2035626e-05\n",
      "LP-Loss 6000 5.5323576e-06 9.809663e-06\n",
      "LP-Loss 7000 4.2318406e-06 7.880076e-06\n",
      "LP-Loss 8000 3.2548737e-06 6.2515983e-06\n",
      "LP-Loss 9000 2.3623904e-06 4.757077e-06\n",
      "LP-Loss 10000 1.6831349e-06 3.5644443e-06\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 312)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.00 (+/- 0.00)\n",
      "Loss Targets 0.001244092\n",
      "Loss SV 8.0880665e-07\n",
      "Loss Vin bound 1.0041353e-05\n",
      "Loss V positive 2.924077e-06\n"
     ]
    }
   ],
   "source": [
    "# Run Mechanistic model (no training) QP (quadratic program) or LP (linear program)\n",
    "# using E. coli core simulation training sets and EB (or UB) bounds\n",
    "\n",
    "# What you can change\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "trainname = 'e_coli_core_UB' # the training set file name\n",
    "size = 10 # number of runs must be lower than the number of element in trainname\n",
    "timestep = int(1.0e4) # LP 1.0e4 QP 1.0e5\n",
    "learn_rate = 0.3 # LP 0.3 QP 1.0\n",
    "decay_rate = 0.9 # only in QP, UB 0.333 EB 0.9\n",
    "write_loss = False # Writes an output file containing loss history mean and std over timesteps\n",
    "write_targets = False # Writes an output file containing true and predicted targets\n",
    "# End of What you can change\n",
    "\n",
    "# Create model and run GD for X and Y randomly drawn from trainingfile\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "model = Neural_Model(trainingfile = trainingfile, \n",
    "              objective=['BIOMASS_Ecoli_core_w_GAM'], \n",
    "              model_type = 'MM_LP', \n",
    "              timestep = timestep, \n",
    "              learn_rate = learn_rate, \n",
    "              decay_rate = decay_rate)\n",
    "\n",
    "# Select a random subset of the training set (of specified size)\n",
    "\n",
    "ID = np.random.choice(model.X.shape[0], size, replace=False)\n",
    "model.X, model.Y = model.X[ID,:], model.Y[ID,:]\n",
    "if model.mediumbound == 'UB':\n",
    "    model.b_ext = model.b_ext[ID,:]\n",
    "if model.mediumbound == 'EB':\n",
    "    model.b_int = model.b_int[ID,:]\n",
    "\n",
    "# Prints a summary of the model before running\n",
    "\n",
    "model.printout()\n",
    "\n",
    "# Make names for output file (if 'write_' flag is set to true)\n",
    "\n",
    "loss_outname = DIRECTORY + \"Result/\" + model.model_type + \"_Loss_\" + \\\n",
    "trainname + \".csv\" if write_loss else None\n",
    "model.loss_outfile = loss_outname\n",
    "targets_outname = DIRECTORY + \"Result/\" + model.model_type + \"_Targets_\" + \\\n",
    "trainname + \".csv\" if write_targets else None\n",
    "model.targets_outfile = targets_outname\n",
    "\n",
    "# Runs the appropriate method\n",
    "\n",
    "if model.model_type is 'MM_QP':\n",
    "    Ypred, Stats = MM_QP(model, verbose=True)\n",
    "if model.model_type is 'MM_LP':\n",
    "    Ypred, Stats = MM_LP(model, verbose=True)\n",
    "\n",
    "# Printing results\n",
    "printout(Ypred, Stats, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf58ecd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "executionInfo": {
     "elapsed": 41456,
     "status": "error",
     "timestamp": 1658841139912,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "4aijtPpxS9Xe",
    "outputId": "46a476d3-3521-4c37-ae52-6d10cd29873c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run Mechanistic model (no training) QP (quadratic program) or LP (linear program)\n",
    "# using E. coli core simulation training sets and EB (or UB) bounds\n",
    "\n",
    "# What you can change\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "trainname = 'e_coli_core_EB' # the training set file name\n",
    "size = 10 # number of runs must be lower than the number of element in trainname\n",
    "timestep = int(1.0e6) # LP 1.0e4 QP 1.0e5\n",
    "learn_rate = 1.0 # LP 0.3 QP 1.0\n",
    "decay_rate = 0.9 # only in QP, UB 0.333 EB 0.9\n",
    "write_loss = False # Writes an output file containing loss history mean and std over timesteps\n",
    "write_targets = False # Writes an output file containing true and predicted targets\n",
    "# End of What you can change\n",
    "\n",
    "# Create model and run GD for X and Y randomly drawn from trainingfile\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "model = Neural_Model(trainingfile = trainingfile, \n",
    "              objective=['BIOMASS_Ecoli_core_w_GAM'], \n",
    "              model_type = 'MM_QP', \n",
    "              timestep = timestep, \n",
    "              learn_rate = learn_rate, \n",
    "              decay_rate = decay_rate)\n",
    "\n",
    "# Select a random subset of the training set (of specified size)\n",
    "ID = np.random.choice(model.X.shape[0], size, replace=False)\n",
    "model.X, model.Y = model.X[ID,:], model.Y[ID,:]\n",
    "if model.mediumbound == 'UB':\n",
    "    model.b_ext = model.b_ext[ID,:]\n",
    "if model.mediumbound == 'EB':\n",
    "    model.b_int = model.b_int[ID,:]\n",
    "\n",
    "# Prints a summary of the model before running\n",
    "model.printout()\n",
    "\n",
    "# Make names for output file (if 'write_' flag is set to true)\n",
    "loss_outname = DIRECTORY + \"Result/\" + model.model_type + \"_Loss_\" \\\n",
    "+ trainname + \".csv\" if write_loss else None\n",
    "model.loss_outfile = loss_outname\n",
    "targets_outname = DIRECTORY + \"Result/\" + model.model_type + \"_Targets_\" \\\n",
    "+ trainname + \".csv\" if write_targets else None\n",
    "model.targets_outfile = targets_outname\n",
    "\n",
    "# Runs the appropriate method\n",
    "if model.model_type is 'MM_QP':\n",
    "    Ypred, Stats = MM_QP(model, loss_outfile=loss_outname, \n",
    "                         targets_outfile= targets_outname,\n",
    "                         verbose=True)\n",
    "if model.model_type is 'MM_LP':\n",
    "    Ypred, Stats = MM_LP(model, loss_outfile=loss_outname, \n",
    "                         targets_outfile= targets_outname,\n",
    "                         verbose=True)\n",
    "# Printing results\n",
    "printout(Ypred, Stats, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d70837",
   "metadata": {
    "id": "HzbEyziKS9Xg",
    "outputId": "0e9a66b6-cd39-4aa8-bdfe-16a4631608ee",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: ./Dataset_model/e_coli_core_UB\n",
      "model type: MM_QP\n",
      "model input dim: 20\n",
      "model output dim: 1\n",
      "model medium bound: UB\n",
      "timestep: 10000\n",
      "training set size (10, 20) (10, 1)\n",
      "noise 0.5\n",
      "GD-Loss 1 2.3497357 0.58461136\n",
      "GD-Loss 10 2.1286168 0.66098446\n",
      "GD-Loss 100 0.68807036 0.15949886\n",
      "GD-Loss 1000 0.17094067 0.048883222\n",
      "GD-Loss 2000 0.112243116 0.03465901\n",
      "GD-Loss 3000 0.08686058 0.028503802\n",
      "GD-Loss 4000 0.071525335 0.024566654\n",
      "GD-Loss 5000 0.061294593 0.021584878\n",
      "GD-Loss 6000 0.05490441 0.019376915\n",
      "GD-Loss 7000 0.048432 0.01873374\n",
      "GD-Loss 8000 0.044350315 0.016383402\n",
      "GD-Loss 9000 0.040097177 0.015305694\n",
      "GD-Loss 10000 0.037610233 0.014153577\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 158)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.10 (+/- 0.03)\n",
      "Loss Targets 0.001111585\n",
      "Loss SV 0.034170542\n",
      "Loss Vin bound 0.20221159\n",
      "Loss V positive 0.0014855479\n",
      "noise 0.1\n",
      "GD-Loss 1 0.47501326 0.122467846\n",
      "GD-Loss 10 0.38130006 0.13565588\n",
      "GD-Loss 100 0.14615281 0.038775574\n",
      "GD-Loss 1000 0.038021643 0.006168148\n",
      "GD-Loss 2000 0.025946546 0.004666064\n",
      "GD-Loss 3000 0.021394977 0.0041978653\n",
      "GD-Loss 4000 0.017953537 0.00272975\n",
      "GD-Loss 5000 0.01612002 0.0028774827\n",
      "GD-Loss 6000 0.015315657 0.0029070498\n",
      "GD-Loss 7000 0.013041636 0.0025741286\n",
      "GD-Loss 8000 0.013403009 0.002066524\n",
      "GD-Loss 9000 0.011851001 0.0022821575\n",
      "GD-Loss 10000 0.011421064 0.0022575574\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 158)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.02 (+/- 0.00)\n",
      "Loss Targets 0.00015246868\n",
      "Loss SV 0.008754591\n",
      "Loss Vin bound 0.051730078\n",
      "Loss V positive 0.0019883483\n",
      "noise 0.01\n",
      "GD-Loss 1 0.040302765 0.014929651\n",
      "GD-Loss 10 0.043605242 0.013471308\n",
      "GD-Loss 100 0.021551762 0.0032731437\n",
      "GD-Loss 1000 0.01295577 0.0017855599\n",
      "GD-Loss 2000 0.010832848 0.0016335463\n",
      "GD-Loss 3000 0.008723472 0.0016224716\n",
      "GD-Loss 4000 0.008132329 0.0009123578\n",
      "GD-Loss 5000 0.0072778994 0.0015002643\n",
      "GD-Loss 6000 0.007845091 0.0021509256\n",
      "GD-Loss 7000 0.006908455 0.0016581449\n",
      "GD-Loss 8000 0.008498592 0.0026306417\n",
      "GD-Loss 9000 0.0077577992 0.0018715493\n",
      "GD-Loss 10000 0.008554951 0.0017394741\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 158)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.01 (+/- 0.00)\n",
      "Loss Targets 9.040833e-05\n",
      "Loss SV 0.0058964994\n",
      "Loss Vin bound 0.004235261\n",
      "Loss V positive 0.002181348\n",
      "noise 0.005\n",
      "GD-Loss 1 0.024253327 0.0059220474\n",
      "GD-Loss 10 0.03250984 0.004300114\n",
      "GD-Loss 100 0.018217592 0.003167705\n",
      "GD-Loss 1000 0.011417119 0.0020049766\n",
      "GD-Loss 2000 0.0108707 0.0014336328\n",
      "GD-Loss 3000 0.008328514 0.0009994135\n",
      "GD-Loss 4000 0.008278303 0.0010883384\n",
      "GD-Loss 5000 0.008122034 0.0013093418\n",
      "GD-Loss 6000 0.007606554 0.0014840455\n",
      "GD-Loss 7000 0.007715703 0.0018213415\n",
      "GD-Loss 8000 0.008206511 0.002801673\n",
      "GD-Loss 9000 0.008397089 0.0014200081\n",
      "GD-Loss 10000 0.007852854 0.0015739804\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 158)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.01 (+/- 0.00)\n",
      "Loss Targets 6.784797e-05\n",
      "Loss SV 0.0049803955\n",
      "Loss Vin bound 0.0010250926\n",
      "Loss V positive 0.0020745764\n",
      "noise 0.001\n",
      "GD-Loss 1 0.0041959966 0.0010934836\n",
      "GD-Loss 10 0.02083666 0.0021951175\n",
      "GD-Loss 100 0.01662457 0.0021410235\n",
      "GD-Loss 1000 0.010959156 0.0011250868\n",
      "GD-Loss 2000 0.0087936465 0.0016638449\n",
      "GD-Loss 3000 0.007834716 0.001145806\n",
      "GD-Loss 4000 0.0072384886 0.0015619427\n",
      "GD-Loss 5000 0.0068340697 0.0013210452\n",
      "GD-Loss 6000 0.008129437 0.0010174217\n",
      "GD-Loss 7000 0.006918711 0.0016620548\n",
      "GD-Loss 8000 0.009609154 0.0019210249\n",
      "GD-Loss 9000 0.009119338 0.002681185\n",
      "GD-Loss 10000 0.008323199 0.0011043978\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 158)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.01 (+/- 0.00)\n",
      "Loss Targets 3.9839746e-05\n",
      "Loss SV 0.005228163\n",
      "Loss Vin bound 0.00061310746\n",
      "Loss V positive 0.0018657271\n",
      "noise 0.0005\n",
      "GD-Loss 1 0.0020922383 0.0004410707\n",
      "GD-Loss 10 0.020746708 0.0021030954\n",
      "GD-Loss 100 0.017589122 0.0018442634\n",
      "GD-Loss 1000 0.01110733 0.0010261724\n",
      "GD-Loss 2000 0.009151478 0.0015694118\n",
      "GD-Loss 3000 0.008169463 0.0012640703\n",
      "GD-Loss 4000 0.007180904 0.0015753557\n",
      "GD-Loss 5000 0.0069270106 0.0010407487\n",
      "GD-Loss 6000 0.0072330995 0.0012335064\n",
      "GD-Loss 7000 0.0072893486 0.0016440472\n",
      "GD-Loss 8000 0.0071456567 0.002402433\n",
      "GD-Loss 9000 0.007952329 0.0016927785\n",
      "GD-Loss 10000 0.008301066 0.0017014496\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 158)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.01 (+/- 0.00)\n",
      "Loss Targets 5.74708e-05\n",
      "Loss SV 0.0054720957\n",
      "Loss Vin bound 0.0005503584\n",
      "Loss V positive 0.0019266801\n"
     ]
    }
   ],
   "source": [
    "# Run Mechanistic model (no training) QP (quadratic program) or LP (linear program)\n",
    "# using E. coli core simulation training sets\n",
    "# with initial X close to solution Y and EB (or UB) bounds\n",
    "\n",
    "# What you can change\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "trainname = 'e_coli_core_UB' # the training set file name (EB or UB)\n",
    "size = 10 # number of runs must be lower than the number of element in trainname\n",
    "timestep = int(1.0e4) # LP 1.0e4 QP 1.0e5\n",
    "learn_rate = 1.0 # LP 0.3 QP 1.0\n",
    "decay_rate = 0.9 # only in QP, UB 0.333 EB 0.9 # try 0.5\n",
    "write_loss = False # Writes an output file containing loss history mean and std over timesteps\n",
    "write_targets = False # Writes an output file containing true and predicted targets\n",
    "model_type = 'MM_QP'\n",
    "# End of What you can change\n",
    "\n",
    "# Draw X and Y randomly drawn from trainingfile\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "model = Neural_Model(trainingfile = trainingfile, \n",
    "              objective=['BIOMASS_Ecoli_core_w_GAM'], \n",
    "              model_type = model_type, \n",
    "              timestep = timestep,\n",
    "              learn_rate = learn_rate,\n",
    "              decay_rate = decay_rate)\n",
    "ID = np.random.choice(model.X.shape[0], size, replace=False)\n",
    "model.X, model.Y, model.Yall = model.X[ID,:], model.Y[ID,:],  model.Yall[ID,:]\n",
    "if model.mediumbound == 'UB':\n",
    "    model.b_ext = model.b_ext[ID,:]\n",
    "if model.mediumbound == 'EB':\n",
    "    model.b_int = model.b_int[ID,:]\n",
    "model.printout()\n",
    "\n",
    "# Create model and run GD X = normal distribution around solution\n",
    "Ypred, Stats = {}, {}\n",
    "noise_set = [0.5, 0.1, 0.01, 0.005, 0.001, 0.0005]\n",
    "for noise in noise_set:\n",
    "    \n",
    "    loss_outname = DIRECTORY + \"Result/\" + str(noise) + \"_noise_\" + \\\n",
    "    model.model_type + \"_Loss_\" + trainname + \".csv\" if write_loss else None\n",
    "    model.loss_outfile = loss_outname\n",
    "    targets_outname = DIRECTORY + \"Result/\" + str(noise) + \"_noise_\" \\\n",
    "    + model.model_type + \"_Targets_\" + trainname + \".csv\" if write_targets else None\n",
    "    model.targets_outfile = targets_outname\n",
    "    \n",
    "    \n",
    "    model.X = np.random.normal(model.Yall, noise*model.Yall)\n",
    "    print('noise', noise)\n",
    "    if model.model_type is 'MM_QP':\n",
    "        Ypred[noise], Stats[noise] = MM_QP(model, verbose=True)\n",
    "    if model.model_type is 'MM_LP':\n",
    "        Ypred[noise], Stats[noise] = MM_LP(model, verbose=True)\n",
    "    \n",
    "    printout(Ypred[noise], Stats[noise], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9287f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "amn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
