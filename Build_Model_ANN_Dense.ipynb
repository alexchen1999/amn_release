{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "725c9c6d"
   },
   "source": [
    "# Install conda on your Colab environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore this first cell if you are running the notebook in a local environment.\n",
    "\n",
    "One can still run it locally but it will have no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40951,
     "status": "ok",
     "timestamp": 1664526150927,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "c4f08880",
    "outputId": "eaae29a9-4739-4b0f-a2a7-56bfa89f0bf0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell first - it will install a conda distribution (mamba)\n",
    "# on your Drive then restart the kernel automatically \n",
    "# (don't worry about the crashing/restarting kernel messages)\n",
    "# It HAS to be runned FIRST everytime you use the notebook in colab\n",
    "\n",
    "import os\n",
    "import sys\n",
    "RunningInCOLAB  = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up your Colab or local environment\n",
    "# Then import libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell in both cases of use (local or Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117260,
     "status": "ok",
     "timestamp": 1664526767265,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "BYwheAEcr-ME",
    "outputId": "8ba41a54-6751-4c00-ed1a-938db78cafb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.ipynb_checkpoints', 'Build_Dataset.ipynb', 'Build_Experimental.ipynb', 'Build_Model_AMN.ipynb', 'Build_Model_ANN_Dense.ipynb', 'Build_Model_MM.ipynb', 'Build_Model_RC.ipynb', 'Build_Model_RF.ipynb', 'Dataset_experimental', 'Dataset_input', 'Dataset_model', 'Duplicate_Model.ipynb', 'environment_amn.yml', 'environment_amn_light.yml', 'Figures', 'Figures.ipynb', 'Library', 'LICENSE', 'README.md', 'Reservoir', 'Result', 'Tutorial.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "RunningInCOLAB  = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    \n",
    "    # Check everything is fine with conda in Colab\n",
    "    import condacolab\n",
    "    condacolab.check()\n",
    "    \n",
    "    # Mount your drive environment in the colab runtime\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    \n",
    "    # Change this variable to your path on Google Drive to which the repo has been cloned\n",
    "    # If you followed the colab notebook 'repo_cloning.ipynb', nothing to change here\n",
    "    repo_path_in_drive = '/content/drive/My Drive/Github/amn_release/'\n",
    "    # Change directory to your repo cloned in your drive\n",
    "    DIRECTORY = repo_path_in_drive\n",
    "    os.chdir(repo_path_in_drive)\n",
    "    # Copy the environment given in the environment_amn_light.yml\n",
    "    !mamba env update -n base -f environment_amn_light.yml\n",
    "    \n",
    "    # This is one of the few Colab-compatible font\n",
    "    font = 'Liberation Sans'\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # In this case the local root of the repo is our working directory\n",
    "    DIRECTORY = './'\n",
    "    font = 'arial'\n",
    "\n",
    "# printing the working directory files. One can check you see the same folders and files as in the git webpage.\n",
    "print(os.listdir(DIRECTORY))\n",
    "\n",
    "from Library.Build_Model import *\n",
    "\n",
    "# We declare this function here and not in the\n",
    "# function-storing python file to modify it easily\n",
    "# as it can change the printouts of the methods\n",
    "def printout(filename, Stats, model, time): \n",
    "    # printing Stats\n",
    "    if Stats == None:\n",
    "        print('Stats for %s failed CPU-time %.4f' % (filename, time))\n",
    "        return\n",
    "    print('Stats for %s CPU-time %.4f' % (filename, time))\n",
    "    print('R2 = %.4f (+/- %.4f) Constraint = %.4f (+/- %.4f)' % \\\n",
    "          (Stats.train_objective[0], Stats.train_objective[1],\n",
    "           Stats.train_loss[0], Stats.train_loss[1]))\n",
    "    print('Q2 = %.4f (+/- %.4f) Constraint = %.4f (+/- %.4f)' % \\\n",
    "          (Stats.test_objective[0], Stats.test_objective[1],\n",
    "           Stats.test_loss[0], Stats.test_loss[1]))\n",
    "\n",
    "def collate_stats(model, parameter, measurement, Y, verbose=False):\n",
    "\n",
    "    if verbose: print(Y.shape, parameter.Y.shape)\n",
    "    Y_true = parameter.Y[:, measurement]\n",
    "    Y_pred = Y[:, measurement]\n",
    "    RQ2 = r2_score(Y_true, Y_pred, multioutput='variance_weighted')\n",
    "    if verbose: print('RQ2 =', RQ2)\n",
    "\n",
    "    X = tf.convert_to_tensor(np.float32(model.X)) # Loss computed of tf tensors\n",
    "    Y = tf.convert_to_tensor(np.float32(Y))\n",
    "    \n",
    "    err = Y_true - Y_pred\n",
    "    L1 = np.linalg.norm(err.reshape(err.shape[0], 1), axis=1)\n",
    "    L2, _ = Loss_SV(Y, model.S)\n",
    "    L3, _ = Loss_Vin(Y, model.Pin, X, model.mediumbound, parameter)\n",
    "    L4, _ = Loss_Vpos(Y, parameter)\n",
    "\n",
    "    L1 = np.square(L1.reshape(1000, 1))\n",
    "    L2 = np.square(L2.numpy())\n",
    "    L3 = np.square(L3.numpy())\n",
    "    L4 = np.square(L4.numpy())\n",
    "\n",
    "    if verbose: \n",
    "        print('Loss_Vout =', np.mean(L1))\n",
    "        print('Loss_SV =', np.mean(L2))\n",
    "        print('Loss_Vin =', np.mean(L3))\n",
    "        print('Loss_Vpos =', np.mean(L4))\n",
    "\n",
    "    L = (L1+L2+L3+L4)/4\n",
    "    L = np.mean(L, axis=0)[0]\n",
    "    if verbose: print('Constraints =', L)\n",
    "    return RQ2, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.99 test = 0.99 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.99 test = 0.99 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.98 test = 0.98 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.99 test = 0.98 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.98 test = 0.98 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "---------- 550\n",
      "Stats for All fluxes CPU-time 326.2052\n",
      "R2 = 0.9850 (+/- 0.0031) Constraint = -1.0000 (+/- 0.0000)\n",
      "Q2 = 0.9844 (+/- 0.0023) Constraint = -1.0000 (+/- 0.0000)\n",
      "(1000, 550) (1000, 550)\n",
      "RQ2 = 0.23296355664280544\n",
      "New Loss_Vout = 0.030904789038871533\n",
      "New Loss_SV = 0.0011422953\n",
      "New Loss_Vin = 5.8182195e-05\n",
      "New Loss_Vpos = 0.0\n",
      "Constraints = 0.008026316667536669\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.98 test = 0.99 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.99 test = 0.99 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.99 test = 0.99 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.99 test = 0.98 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.86 test = 0.85 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "---------- 550\n",
      "Stats for All fluxes CPU-time 333.6338\n",
      "R2 = 0.9614 (+/- 0.0517) Constraint = -1.0000 (+/- 0.0000)\n",
      "Q2 = 0.9593 (+/- 0.0552) Constraint = -1.0000 (+/- 0.0000)\n",
      "(1000, 550) (1000, 550)\n",
      "RQ2 = 0.215446257833794\n",
      "New Loss_Vout = 0.028983282298013092\n",
      "New Loss_SV = 0.0016017918\n",
      "New Loss_Vin = 7.163726e-05\n",
      "New Loss_Vpos = 0.0\n",
      "Constraints = 0.007664177881813463\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.99 test = 0.99 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.99 test = 0.99 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.98 test = 0.98 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.86 test = 0.85 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 295050\n",
      "---------- 550\n",
      "---------- 550\n",
      "train = 0.85 test = 0.86 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "---------- 550\n",
      "Stats for All fluxes CPU-time 348.6492\n",
      "R2 = 0.9349 (+/- 0.0644) Constraint = -1.0000 (+/- 0.0000)\n",
      "Q2 = 0.9338 (+/- 0.0642) Constraint = -1.0000 (+/- 0.0000)\n",
      "(1000, 550) (1000, 550)\n",
      "RQ2 = -0.5272036095944574\n",
      "New Loss_Vout = 0.06186724382847927\n",
      "New Loss_SV = 0.0024611664\n",
      "New Loss_Vin = 7.244457e-05\n",
      "New Loss_Vpos = 0.0\n",
      "Constraints = 0.01610021374377827\n",
      "**** Epoch 100 Q2 (biomass) = -0.0263 (+/- 0.3543) Loss = 0.0106 (+/- 0.0039) epochs = 100\n"
     ]
    }
   ],
   "source": [
    "# Create and train an ANN regression model (dense architecture) for E. coli \n",
    "\n",
    "# What you can change\n",
    "seed = 2\n",
    "np.random.seed(seed=seed)\n",
    "# trainname = 'e_coli_core_EB'\n",
    "trainname = 'iML1515_UB'\n",
    "xfold = 5\n",
    "Maxloop = 3\n",
    "# End of what you can change\n",
    "\n",
    "# Load training set\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "cobramodel = cobra.io.read_sbml_model(trainingfile+'.xml')\n",
    "parameter = TrainingSet()\n",
    "parameter.load(trainingfile)\n",
    "\n",
    "for epochs in [100]: # range(0, 101, 5):\n",
    "    RQ2, Loss, RQ2_ori, Loss_ori = [], [], [], []\n",
    "    for Nloop in range(Maxloop):\n",
    "        model = Neural_Model(trainingfile = trainingfile,\n",
    "                         model_type = 'ANN_Dense',\n",
    "                         #objective=['BIOMASS_Ecoli_core_w_GAM'],  \n",
    "                         scaler=True,\n",
    "                         n_hidden = 1, hidden_dim = 500,\n",
    "                         epochs = epochs, xfold = xfold)\n",
    "\n",
    " \n",
    "\n",
    "        SIZE = 1000\n",
    "\n",
    "        ID = np.random.choice(model.X.shape[0], \n",
    "\n",
    "                            size=SIZE, replace=True)\n",
    "\n",
    "        Xtrain,  Ytrain  = model.X[ID,:], model.Y[ID,:]\n",
    "\n",
    "        model.X, model.Y = Xtrain, Ytrain\n",
    "\n",
    "        parameter.X, parameter.Y = Xtrain, Ytrain\n",
    "\n",
    "        # print(model.Y[0])\n",
    "        # Train and evaluate\n",
    "        start_time = time.time()\n",
    "        \"\"\"try:\n",
    "            reservoir, pred, stats, _ = train_evaluate_model(model, verbose=False)\n",
    "        except:\n",
    "            reservoir, pred, stats, _ = None, np.zeros(model.Y.shape), None, None\"\"\"\n",
    "        reservoir, pred, stats, _ = train_evaluate_model(model, verbose=False)\n",
    "        # Printing cross-validation results\n",
    "        delta_time = time.time() - start_time\n",
    "        printout('All fluxes', stats, reservoir, delta_time)\n",
    " \n",
    "        # Collate all predicted Y and get stats and constraints\n",
    "        biomass_index = get_index_from_id('BIOMASS_Ec_iML1515_core_75p37M', cobramodel.reactions) # 'BIOMASS_Ecoli_core_w_GAM'\n",
    "        rq2, l = collate_stats(model, parameter, biomass_index, pred, verbose=True)\n",
    "        RQ2.append(rq2)\n",
    "        Loss.append(l)\n",
    "\n",
    "    # Print stats averaged over all iterations\n",
    "    rqt = 'R2 (biomass)' if xfold < 2 else 'Q2 (biomass)'\n",
    "    print('**** Epoch', epochs, rqt, '= %.4f (+/- %.4f) Loss = %.4f (+/- %.4f) epochs = %d' \\\n",
    "          % (np.mean(RQ2), np.std(RQ2), np.mean(Loss), np.std(Loss), epochs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LNzx86fAt34-"
   },
   "source": [
    "# Create and Train ANN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbr parameters: 8904\n",
      "train = 0.71 test = -0.10 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.67 test = 0.54 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.64 test = 0.60 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.72 test = 0.46 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.68 test = 0.48 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "Stats for All fluxes CPU-time 416.7927\n",
      "R2 = 0.6856 (+/- 0.0293) Constraint = -1.0000 (+/- 0.0000)\n",
      "Q2 = 0.3978 (+/- 0.2509) Constraint = -1.0000 (+/- 0.0000)\n",
      "(50, 154) (50, 154)\n",
      "RQ2 = 0.8113039196567445\n",
      "Loss_Vout = 0.002969156360921121\n",
      "Loss_SV = 0.16527662\n",
      "Loss_Vin = 0.2739699\n",
      "Constraints = 0.14740522061993575\n",
      "nbr parameters: 8904\n",
      "train = 0.73 test = -0.01 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.60 test = 0.39 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.72 test = 0.46 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.71 test = 0.45 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.67 test = 0.44 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "Stats for All fluxes CPU-time 398.8768\n",
      "R2 = 0.6873 (+/- 0.0489) Constraint = -1.0000 (+/- 0.0000)\n",
      "Q2 = 0.3454 (+/- 0.1816) Constraint = -1.0000 (+/- 0.0000)\n",
      "(50, 154) (50, 154)\n",
      "RQ2 = 0.8495179006474769\n",
      "Loss_Vout = 0.0023678546034688643\n",
      "Loss_SV = 0.32870498\n",
      "Loss_Vin = 0.2762464\n",
      "Constraints = 0.2024397454289395\n",
      "nbr parameters: 8904\n",
      "train = 0.72 test = 0.37 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.62 test = 0.56 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.73 test = 0.49 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.75 test = 0.35 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "nbr parameters: 8904\n",
      "train = 0.70 test = 0.35 loss-train = -1.000000 loss-test = -1.000000 iter=0\n",
      "Stats for All fluxes CPU-time 386.3483\n",
      "R2 = 0.7068 (+/- 0.0442) Constraint = -1.0000 (+/- 0.0000)\n",
      "Q2 = 0.4239 (+/- 0.0843) Constraint = -1.0000 (+/- 0.0000)\n",
      "(50, 154) (50, 154)\n",
      "RQ2 = 0.8441090881612366\n",
      "Loss_Vout = 0.002452962942599894\n",
      "Loss_SV = 0.121055536\n",
      "Loss_Vin = 0.2725631\n",
      "Constraints = 0.1320238662586211\n",
      "Q2 (biomass) = 0.8350 (+/- 0.0169) Loss = 0.1606 (+/- 0.0302)\n"
     ]
    }
   ],
   "source": [
    "# What you can change\n",
    "seed = 2\n",
    "np.random.seed(seed=seed)\n",
    "trainname = 'e_coli_core_UB_50'\n",
    "xfold = 5\n",
    "Maxloop = 3\n",
    "# End of what you can change\n",
    "\n",
    "# Load training set\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "cobramodel = cobra.io.read_sbml_model(trainingfile+'.xml')\n",
    "parameter = TrainingSet()\n",
    "parameter.load(trainingfile)\n",
    "RQ2, Loss = [], []\n",
    "\n",
    "for Nloop in range(Maxloop):\n",
    "    model = Neural_Model(trainingfile = trainingfile,\n",
    "                         model_type = 'ANN_Dense',\n",
    "                         scaler=True, batch_size=5,\n",
    "                         train_rate=1e-3, activation=\"relu\",\n",
    "                         n_hidden = 1, hidden_dim = 50,\n",
    "                         epochs = 500, xfold = xfold)\n",
    "    # Train and evaluate\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        reservoir, pred, stats, _ = train_evaluate_model(model, verbose=False)\n",
    "    except:\n",
    "        reservoir, pred, stats, _ = None, np.zeros(model.Y.shape), None, None\n",
    "    # Printing cross-validation results\n",
    "    delta_time = time.time() - start_time\n",
    "    printout('All fluxes', stats, reservoir, delta_time)\n",
    " \n",
    "    # Collate all predicted Y and get stats and constraints\n",
    "    biomass_index = get_index_from_id('BIOMASS_Ecoli_core_w_GAM',cobramodel.reactions)\n",
    "    rq2, l = collate_stats(model, parameter, biomass_index, pred, verbose=True)\n",
    "    RQ2.append(rq2)\n",
    "    Loss.append(l)\n",
    "\n",
    "# Print stats averaged over all iterations\n",
    "rqt = 'R2 (biomass)' if xfold < 2 else 'Q2 (biomass)'\n",
    "print(rqt, '= %.4f (+/- %.4f) Loss = %.4f (+/- %.4f)' \\\n",
    "      % (np.mean(RQ2), np.std(RQ2), np.mean(Loss), np.std(Loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train an ANN classification model (dense architecture) for P. putida\n",
    "\n",
    "# What you can change \n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "trainname = 'IJN1463_EXP' # can change EB by UB\n",
    "# End of What you can change\n",
    "\n",
    "# Create model \n",
    "trainingfile = DIRECTORY+'Dataset_input/'+trainname\n",
    "X, Y = read_XY(trainingfile, 196)\n",
    "model = Neural_Model(model_type = 'ANN_Dense',\n",
    "                     n_hidden = 1, hidden_dim = 100, batch_size=5,\n",
    "                     regression = False, activation = 'sigmoid', \n",
    "                     input_dim = 196, output_dim = 1,\n",
    "                     epochs = 500, xfold = 10,\n",
    "                     verbose=True) \n",
    "\n",
    "model.X, model.Y = X, Y\n",
    "model.printout()\n",
    "\n",
    "# Train\n",
    "start_time = time.time()\n",
    "reservoir, pred, stats, _ = train_evaluate_model(model, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "# Printing cross-validation results\n",
    "printout('dump', stats, model, delta_time)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Build_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('AMN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6c18e9696c1974a25314c7f50070d762f9d347da5760adda9ec45ed5120fd09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
